{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b0f8535",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/casangi/graphviper/blob/main/docs/graph_building_tutorial_processing_set.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed122f09-ead5-4a22-a70b-7702d556e7fe",
   "metadata": {},
   "source": [
    "# GraphVIPER Tutorial\n",
    "\n",
    "This tutorial provides examples of how `GraphVIPER` can be used to build `Dask` graphs by mapping a dictionary-based container of `xarray.Datasets` to `Dask` graph nodes, followed by a reduction step. The dictionary of `Datasets` used in this tutorial is referred to as a `Processing Set`, although any dictionary containing `xarray.Datasets` can be used. `GraphVIPER` [map](https://graphviper.readthedocs.io/en/latest/_api/autoapi/graphviper/graph_tools/map/index.html#module-contents) can be thought of as a generalization of the [xarray.map_blocks](https://docs.xarray.dev/en/stable/generated/xarray.map_blocks.html) that can be applied to more than one `xarray.Dataset`. The graphs are built using [dask.delayed](https://docs.dask.org/en/stable/delayed.html).\n",
    "\n",
    "The following types of mapping are supported:\n",
    "\n",
    "- Partitions defined by any combination of the coordinates in the `Processing Set`.\n",
    "- More than one `xarray.Dataset` can be assigned to a single mapping node.\n",
    "- `xarray.Dataset` partitions assigned to different nodes can have coordinates that overlap.\n",
    "\n",
    "The tutorial will cover the following examples:\n",
    "\n",
    "- Frequency Map Reduce: This example explains the concepts of `parallel_coords` and `node_task_data_mapping` that define parallelism and mapping.\n",
    "- Overlapping Frequency Map Reduce.\n",
    "- Baseline and Frequency Map Reduce.\n",
    "- Time Map Reduce.\n",
    "\n",
    "`GraphVIPER` provides improvements over the [CNGI prototype](https://cngi-prototype.readthedocs.io/en/stable/development.html):\n",
    "\n",
    "- There is a clear separation between the concurrency layer ([GraphVIPER](https://graphviper.readthedocs.io/en/latest/)) and the domain layer (science code, [AstroVIPER](https://github.com/casangi/astroviper)).\n",
    "- The memory backpressure issue was solved by incorporating the loading of data into the compute nodes. Memory backpressure is an issue for Radio Astronomy cube imaging that has to create large in-memory image cubes, which `Dask` is not aware of, causing `Dask` to be overeager in loading data from disk into memory. `Dask` might provide an alternative solution in the future where graph nodes can be annotated with expected memory usage.\n",
    "- The number of graph nodes has been minimized; this was also solved by incorporating the loading of data into the compute nodes. When `Xarray` backed `Dask` datasets are used, a node is created for each data variable, and since Radio Astronomy datasets have numerous data variables, it led to a bloated graph that impacted scaling performance.\n",
    "- Multiple `xarray.Datasets` can be processed together with overlap. This cannot be done with the current `Xarray` functionality, such as [xarray.map_blocks](https://docs.xarray.dev/en/stable/generated/xarray.map_blocks.html).\n",
    "- Using a [Dask plugin](https://distributed.dask.org/en/latest/plugins.html), the `Dask Scheduler` has been modified so that data can be cached to a local disk when multiple passes over larger-than-memory data have to be done. This reduces clustered file system or binary object store access (see [GraphVIPER Client](https://graphviper.readthedocs.io/en/latest/_api/autoapi/graphviper/dask/client/index.html)).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbf2b16",
   "metadata": {},
   "source": [
    "## Install GraphVIPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7850f0a-f46a-48cc-98b1-fde794af919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphVIPER version 0.0.3 already installed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    import graphviper\n",
    "\n",
    "    print(\"GraphVIPER version\", graphviper.__version__, \"already installed.\")\n",
    "except ImportError as e:\n",
    "    print(e)\n",
    "    print(\"Installing GraphVIPER\")\n",
    "\n",
    "    os.system(\"pip install graphviper\")\n",
    "\n",
    "    import graphviper\n",
    "\n",
    "    print(\"GraphVIPER version\", graphviper.__version__, \" installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa8d3c-6fd9-474f-9223-6da8856ab948",
   "metadata": {},
   "source": [
    "## Download and Convert Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f2b674-78e3-4dbb-9079-2b46825e1f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[38;2;128;05;128m2024-02-02 11:47:47,899\u001b[0m] \u001b[38;2;50;50;205m    INFO\u001b[0m\u001b[38;2;112;128;144m  graphviper: \u001b[0m File exists: Antennae_North.cal.lsrk.split.ms \n"
     ]
    }
   ],
   "source": [
    "graphviper.utils.data.download(file=\"Antennae_North.cal.lsrk.split.ms\")\n",
    "\n",
    "from xradio.vis.convert_msv2_to_processing_set import convert_msv2_to_processing_set\n",
    "\n",
    "# The chunksize on disk. Chunksize can be specified for any of the following dimensions :\n",
    "# time, baselin_id (interferometer) / antenna_id (single dish), frequency, and polarization.\n",
    "chunks_on_disk = {\"frequency\": 3}\n",
    "\n",
    "infile = \"Antennae_North.cal.lsrk.split.ms\"\n",
    "outfile = \"Antennae_North.cal.lsrk.split.vis.zarr\"\n",
    "\n",
    "convert_msv2_to_processing_set(\n",
    "    in_file=infile,\n",
    "    out_file=outfile,\n",
    "    parallel=False,\n",
    "    overwrite=True,\n",
    "    main_chunksize=chunks_on_disk,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682bb1c-c377-47f2-9faa-271108954d8f",
   "metadata": {},
   "source": [
    "## Setup Dask Cluster\n",
    "To simplify things we are going to start of by just using a single process (everything will run in serial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e50179-3486-4454-9036-ff55d24346fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[38;2;128;05;128m2024-02-02 11:47:49,135\u001b[0m] \u001b[38;2;50;50;205m    INFO\u001b[0m\u001b[38;2;112;128;144m  graphviper: \u001b[0m Checking parameter values for \u001b[38;2;50;50;205mclient\u001b[0m.\u001b[38;2;50;50;205mlocal_client\u001b[0m \n",
      "[\u001b[38;2;128;05;128m2024-02-02 11:47:49,137\u001b[0m] \u001b[38;2;50;50;205m    INFO\u001b[0m\u001b[38;2;112;128;144m  graphviper: \u001b[0m /export/home/ajax/jhoskins/Development/graphviper-logger/ \n",
      "[\u001b[38;2;128;05;128m2024-02-02 11:47:49,138\u001b[0m] \u001b[38;2;50;50;205m    INFO\u001b[0m\u001b[38;2;112;128;144m  graphviper: \u001b[0m Searching \u001b[38;2;50;50;205m/export/home/ajax/jhoskins/Development/graphviper-logger/\u001b[0m for configuration file, please wait ... \n",
      "[\u001b[38;2;128;05;128m2024-02-02 11:47:49,176\u001b[0m] \u001b[38;2;255;160;0m WARNING\u001b[0m\u001b[38;2;112;128;144m  graphviper: \u001b[0m It is recommended that the local cache directory be set using the \u001b[38;2;50;50;205mdask_local_dir\u001b[0m parameter. \n",
      "[\u001b[38;2;128;05;128m2024-02-02 11:47:50,329\u001b[0m] \u001b[38;2;50;50;205m    INFO\u001b[0m\u001b[38;2;112;128;144m  graphviper: \u001b[0m Created client <MenrvaClient: 'tcp://127.0.0.1:36335' processes=2 threads=2, memory=7.45 GiB> \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'http://127.0.0.1:8787/status'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "\n",
    "from graphviper.dask.client import local_client\n",
    "\n",
    "viper_client = local_client(\n",
    "    cores=2, \n",
    "    memory_limit=\"4GB\",\n",
    "    autorestrictor=True,\n",
    "    log_params={\n",
    "        'logger_name': \"graphviper\",\n",
    "        'log_to_term': True,\n",
    "        'log_level': 'INFO',\n",
    "        'log_to_file': False,\n",
    "        'log_file': None\n",
    "    },\n",
    "    worker_log_params={\n",
    "        'logger_name': \"graphviper\",\n",
    "        'log_to_term': True,\n",
    "        'log_level': 'INFO',\n",
    "        'log_to_file': False,\n",
    "        'log_file': None\n",
    "    }\n",
    ")\n",
    "\n",
    "viper_client.dashboard_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fbc95-5c2e-492a-83ab-022f93637dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.set(scheduler=\"synchronous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a13d40-5654-4011-9467-d269fe601826",
   "metadata": {},
   "source": [
    "## Inspect the Processing Set\n",
    "\n",
    "The `read_processing_set` is a lazy function, so no data is loaded into memory; only metadata is loaded (the `load_processing_set` will load everything into memory). Metadata is defined as everything that is not an `xarray.datavariable`. Note that a `Processing Set` does not have to be used with `GraphVIPER`, and any dictionary of `xarray.datasets` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774b2011-8921-48fb-90dc-f56689862110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "ps_name = \"Antennae_North.cal.lsrk.split.vis.zarr\"\n",
    "\n",
    "from xradio.vis.read_processing_set import read_processing_set\n",
    "\n",
    "intents = [\"OBSERVE_TARGET#ON_SOURCE\"]\n",
    "fields = None\n",
    "ps = read_processing_set(\n",
    "    ps_name=\"Antennae_North.cal.lsrk.split.vis.zarr\",\n",
    "    intents=intents,\n",
    "    fields=fields,\n",
    ")\n",
    "display(ps.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b44df1-613b-4eaf-9c04-55bad4c5ced3",
   "metadata": {},
   "source": [
    "## Inspect a single MS v4\n",
    "\n",
    "The `xarray.datasets` within a Processing Set are called Measurement Set v4 (`ms_v4`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c1b6da-4c81-4f97-9000-0f5784dfbc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_xds = ps[\n",
    "    \"Antennae_North.cal.lsrk.split_ddi_0_intent_OBSERVE_TARGET#ON_SOURCE_field_id_0\"\n",
    "]\n",
    "ms_xds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e880b",
   "metadata": {},
   "source": [
    "## Nomenclature\n",
    "\n",
    "- input data: A dictionary of `xarray.datasets` or a `processing_set`.\n",
    "- n_datasets: The number of `xarray.Datasets` in the input data.\n",
    "- i_dim: The ith dimension name.\n",
    "- n_dims: The number of dimensions over which parallelism will occur.\n",
    "- n_dim_i_chunks: Number of chunks into which the dimension coordinate `dim_i` has been divided.\n",
    "- n_nodes: Number of nodes in the mapping stage of a Map Reduce graph.\n",
    "- _{}: If curly brackets are preceded by an underscore, it indicates a subscript and not a dictionary value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7e11c7-18f8-4174-a713-a020a8f91273",
   "metadata": {},
   "source": [
    "## How Graph Parallelism is Specified: ```parallel_coords```\n",
    "\n",
    "The `parallel_coords` is a dictionary where the keys are dimensions over which parallelism will occur and can be any of the dimension coordinate names present in the input data. For the `ms_v4` `xarray.dataset`, the options include time, baseline_id (interferometer) / antenna_id (single dish), frequency, and polarization. Each dimension coordinate name is associated with a dictionary that describes the data selection for that dimension in each node of the mapping stage of the graph.\n",
    "\n",
    "The structure of the `parallel_coordinates`:\n",
    "```\n",
    "        parallel_coords = {\n",
    "            dim_0: {\n",
    "                'data': 1D list/np.ndarray of Number,\n",
    "                'data_chunks': {\n",
    "                    0 : 1D list/np.ndarray of Number,\n",
    "                    ⋮\n",
    "                    n_dim_i_chunks-1 : ...,\n",
    "                }\n",
    "                'data_chunk_edges': 1D list/np.ndarray of Number,\n",
    "                'dims': (dim_0,), \n",
    "                'attrs': measure attribute,\n",
    "            }\n",
    "            ⋮\n",
    "            dim_{n_dims-1}: ...\n",
    "        }\n",
    "```\n",
    "\n",
    "The `dim_i` dictionaries have keys with the following meanings:\n",
    "\n",
    "- `data`: An array containing all the coordinate values associated with that dimension. These values do not necessarily have to match the values in the coordinates of the input data (dictionary of `xarray.datasets` or `processing_set`), as those are interpolated onto these values. The minimum and maximum values can be respectively larger or smaller than the values in the coordinates of individual `xarray.datasets`; this will simply exclude that data from being processed. It's important to note that the `parallel_coords` and the input data coordinates must have the same measures attributes (reference frame, units, etc.).\n",
    "- `data_chunks`: A dictionary where the data is broken into chunks with integer keys. This chunking determines the parallelism of the graph. The values in the chunks can overlap.\n",
    "- `data_chunks_edges`: An array with the start and end values of each chunk.\n",
    "- `dims`: The dimension coordinate name.\n",
    "- `attrs`: The `XRADIO` measures attributes of the data (refer to [XRADIO documentation](https://docs.google.com/spreadsheets/d/14a6qMap9M5r_vjpLnaBKxsR9TF4azN5LVdOxLacOX-s/edit#gid=1504318014)).\n",
    "\n",
    "The combinations of all the chunks in `parallel_coords` determine the parallelism of the graph. For example, if you have `parallel_coords` with 5 `time` and 3 `frequency` chunks, you would have 15-way parallelism (5x3).\n",
    "\n",
    "This description may seem somewhat convoluted, but the following examples should help clarify things."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa2f48",
   "metadata": {},
   "source": [
    "## Frequency Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33094606-edf4-414b-800c-589146c4a55a",
   "metadata": {},
   "source": [
    "### Create Parallel Coordinates\n",
    "\n",
    "GraphVIPER offers a convenient function, `make_parallel_coord`, that converts any [XRADIO measures](https://docs.google.com/spreadsheets/d/14a6qMap9M5r_vjpLnaBKxsR9TF4azN5LVdOxLacOX-s/edit#gid=1504318014) to a `parallel_coord`. In this case, we will use the frequency coordinate of one of the datasets in the `processing_set`. It's worth noting that all datasets in this `processing_set` have the same frequency coordinates but differing time coordinates. This is the case because they represent the same spectral window but different fields in a Mosaic observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a781e-9b81-46c6-9c16-7510d0f4eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.coordinate_utils import make_parallel_coord\n",
    "from graphviper.utils.display import dict_to_html\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "parallel_coords = {}\n",
    "n_chunks = 3\n",
    "parallel_coords[\"frequency\"] = make_parallel_coord(\n",
    "    coord=ms_xds.frequency, n_chunks=n_chunks\n",
    ")\n",
    "display(HTML(dict_to_html(parallel_coords[\"frequency\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679dd6a",
   "metadata": {},
   "source": [
    "The display of the frequency `parallel_coords` clearly shows how the data was split into 3 chunks. All the chunks must have the same number of values, except the last chunk, which can have fewer. GraphVIPER also has convenience functions that can create frequency and time coordinate measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f9152-a57d-4c26-bd32-7736dffa850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.coordinate_utils import make_frequency_coord\n",
    "\n",
    "n_chunks = 3\n",
    "\n",
    "coord = make_frequency_coord(\n",
    "    freq_start=343928096685.9587,\n",
    "    freq_delta=11231488.981445312,\n",
    "    n_channels=8,\n",
    "    velocity_frame=\"lsrk\",\n",
    ")\n",
    "parallel_coords[\"frequency\"] = make_parallel_coord(\n",
    "    coord=ms_xds.frequency, n_chunks=n_chunks\n",
    ")\n",
    "display(HTML(dict_to_html(parallel_coords[\"frequency\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b99bcd",
   "metadata": {},
   "source": [
    "### Create Node Task Data Mapping\n",
    "\n",
    "Now, the coordinates in the input data must be mapped onto the `parallel_coords`. This is achieved using the `interpolate_data_coords_onto_parallel_coords` function, which produces the `node_task_data_mapping`. It is a dictionary where each key is the node id of the nodes in the mapping stage of the graph\n",
    "\n",
    "Structure of  node_task_data_mapping:\n",
    "```\n",
    "    node_task_data_mapping = {\n",
    "        0 : {\n",
    "            'chunk_indices': tuple of int,\n",
    "            'parallel_dims': tuple of str,\n",
    "            'data_selection': {\n",
    "                    dataset_name_0: {\n",
    "                            dim_0: slice,\n",
    "                            ⋮\n",
    "                            dim_(n_dims-1): slice\n",
    "                    }\n",
    "                    ⋮\n",
    "                    dataset_name_(n_dataset-1): ...\n",
    "            }\n",
    "            'task_coords': #Is a measures\n",
    "                dim_0:{\n",
    "                    'data': list/np.ndarray of Number,\n",
    "                    'dims': str,\n",
    "                    'attrs': measure attribute,\n",
    "                }\n",
    "                ⋮\n",
    "                dim_(n_dims-1): ...\n",
    "            }\n",
    "        ⋮\n",
    "        n_nodes-1 : ...\n",
    "    }\n",
    "```\n",
    "\n",
    "Each node id dictionary has the keys with the following meaning:\n",
    "\n",
    "- `chunk_indices`: The indices assigned to the data chunks in the `parallel_coords`. There must be an index for each `parallel_dims`.\n",
    "- `parallel_dims`: The dimension coordinates over which parallelism will occur.\n",
    "- `data_selection`: A dictionary where the keys are the names of the datasets in the `processing_set`, and the values are dictionaries with the coordinates and accompanying slices. If a coordinate is not included, all values will be selected.\n",
    "- `task_coords`: The chunk of the parallel_coord that is assigned to this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb8a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.coordinate_utils import (\n",
    "    interpolate_data_coords_onto_parallel_coords,\n",
    ")\n",
    "\n",
    "node_task_data_mapping = interpolate_data_coords_onto_parallel_coords(\n",
    "    parallel_coords, ps\n",
    ")\n",
    "display(HTML(dict_to_html(node_task_data_mapping)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbea156-e5e0-45eb-8a40-ca1f11c97e1b",
   "metadata": {},
   "source": [
    "### Create a chunk function and map graph\n",
    "\n",
    "The `map` function combines a `node_task_data_mapping` and a `node_task` to create the map portion of the graph. The `node_task` must be a function with a single dictionary input and a single output as is the `my_func` in the example below. The `map` function will pass the `input_parms` dictionary to the `node_task` and add the following items from the `node_task_data_mapping`:\n",
    "\n",
    "- chunk_indices\n",
    "- parallel_dims\n",
    "- data_selection\n",
    "- task_coords\n",
    "- task_id\n",
    "\n",
    "If local caching is enabled the following will also be included with the `input_params` dictionary:\n",
    "\n",
    "- date_time\n",
    "- viper_local_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a5da8a-6b40-4912-903b-e9c9ee196fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.map import map\n",
    "import dask\n",
    "from graphviper.utils.display import dict_to_html\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def my_func(input_parms):\n",
    "    display(HTML(dict_to_html(input_parms)))\n",
    "\n",
    "    print(\"*\" * 30)\n",
    "    return input_parms[\"test_input\"]\n",
    "\n",
    "\n",
    "input_parms = {}\n",
    "input_parms[\"test_input\"] = 42\n",
    "\n",
    "graph = map(\n",
    "    input_data=ps,\n",
    "    node_task_data_mapping=node_task_data_mapping,\n",
    "    node_task=my_func,\n",
    "    input_parms=input_parms,\n",
    ")\n",
    "\n",
    "dask.visualize(graph, filename=\"map_graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd60c8-e248-4356-9183-35fabdf27e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f509ded-23dd-4c08-aabc-d19678a7bbb8",
   "metadata": {},
   "source": [
    "### Run Map Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252e010a-b04f-43dd-8e4f-798d31267b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.compute(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291e9e20-8b36-4cb2-82b2-90fdfaf37a01",
   "metadata": {},
   "source": [
    "### Reduce Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3286a1c5-cd4c-45e1-9ada-c14802538b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools import reduce\n",
    "import numpy as np\n",
    "\n",
    "def my_sum(graph_inputs, input_parms):\n",
    "    print(graph_inputs)\n",
    "    return np.sum(graph_inputs) + input_parms[\"test_input\"]\n",
    "\n",
    "input_parms = {}\n",
    "input_parms[\"test_input\"] = 5\n",
    "graph_reduce = reduce(\n",
    "    graph, my_sum, input_parms, mode=\"single_node\"\n",
    ")  # mode \"tree\",\"single_node\"\n",
    "dask.visualize(graph_reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools import reduce\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def my_sum(graph_inputs, input_parms):\n",
    "    print(graph_inputs)\n",
    "    return np.sum(graph_inputs) + input_parms[\"test_input\"]\n",
    "\n",
    "\n",
    "input_parms = {}\n",
    "input_parms[\"test_input\"] = 5\n",
    "graph_reduce = reduce(\n",
    "    graph, my_sum, input_parms, mode=\"tree\"\n",
    ")  # mode \"tree\",\"single_node\"\n",
    "dask.visualize(graph_reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717022f0-fed9-461a-9943-ea6f31714249",
   "metadata": {},
   "source": [
    "### Run Map Reduce Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199eb981-3852-40d6-915c-70cc63818677",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.compute(graph_reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57673d4b-5e5e-4e1c-bf54-275ea526178e",
   "metadata": {},
   "source": [
    "## Overlapping Frequency Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33871abd-78f6-48c1-9c7c-58388435d270",
   "metadata": {},
   "source": [
    "### Create Parallel Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278ba9b-9dcf-4a15-8265-b5e33c998d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.utils.display import dict_to_html\n",
    "import dask\n",
    "\n",
    "dask.config.set(scheduler=\"synchronous\")\n",
    "from xradio.vis.read_processing_set import read_processing_set\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "\n",
    "ps = read_processing_set(\n",
    "    ps_name=\"Antennae_North.cal.lsrk.split.vis.zarr\",\n",
    "    intents=[\"OBSERVE_TARGET#ON_SOURCE\"],\n",
    ")\n",
    "ms_xds = ps.get(1)\n",
    "n_chunks = 3\n",
    "\n",
    "parallel_coords = {}\n",
    "freq_coord = ms_xds.frequency.to_dict()\n",
    "freq_coord[\"data_chunks\"] = {\n",
    "    0: freq_coord[\"data\"][0:4],\n",
    "    1: freq_coord[\"data\"][3:7],\n",
    "    2: freq_coord[\"data\"][4:8],\n",
    "}\n",
    "parallel_coords[\"frequency\"] = freq_coord\n",
    "\n",
    "display(HTML(dict_to_html(parallel_coords[\"frequency\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f37c4",
   "metadata": {},
   "source": [
    "### Create Node Task Data Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.coordinate_utils import (\n",
    "    interpolate_data_coords_onto_parallel_coords,\n",
    ")\n",
    "\n",
    "node_task_data_mapping = interpolate_data_coords_onto_parallel_coords(\n",
    "    parallel_coords, ps\n",
    ")\n",
    "display(HTML(dict_to_html(node_task_data_mapping)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4660e626-9561-4817-9bd5-cce3b371853e",
   "metadata": {},
   "source": [
    "### Map Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7fd02-63e0-438f-b9a5-dde9789a8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.map import map\n",
    "import dask\n",
    "from IPython.display import display, HTML\n",
    "from xradio.vis.read_processing_set import read_processing_set\n",
    "\n",
    "\n",
    "def my_func(input_parms):\n",
    "    display(HTML(dict_to_html(input_parms)))\n",
    "\n",
    "    print(\"*\" * 30)\n",
    "    return input_parms[\"test_input\"]\n",
    "\n",
    "\n",
    "# ['test_input', 'input_data_name', 'viper_local_dir', 'date_time', 'data_sel', 'chunk_coords', 'chunk_indx', 'chunk_id', 'parallel_dims']\n",
    "input_parms = {}\n",
    "input_parms[\"test_input\"] = 42\n",
    "\n",
    "ps = read_processing_set(\n",
    "    ps_name=\"Antennae_North.cal.lsrk.split.vis.zarr\",\n",
    "    intents=[\"OBSERVE_TARGET#ON_SOURCE\"],\n",
    ")\n",
    "\n",
    "graph = map(\n",
    "    input_data=ps,\n",
    "    node_task_data_mapping=node_task_data_mapping,\n",
    "    node_task=my_func,\n",
    "    input_parms=input_parms,\n",
    ")\n",
    "\n",
    "dask.visualize(graph, filename=\"map_graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbbc632-2744-4364-bac0-0c07670ff5d6",
   "metadata": {},
   "source": [
    "### Run Map Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08fd267-270e-410b-9a8e-122c351a70c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.compute(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16514b4c-f138-48db-88e3-7d204747bff7",
   "metadata": {},
   "source": [
    "## Baseline and Frequency Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f98381-34c8-400f-a7c0-b4fba291b330",
   "metadata": {},
   "source": [
    "### Create Parallel Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54625049-166f-4748-ade2-2e0164d253b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.utils.display import dict_to_html\n",
    "from graphviper.graph_tools.coordinate_utils import make_parallel_coord\n",
    "import dask\n",
    "\n",
    "dask.config.set(scheduler=\"synchronous\")\n",
    "\n",
    "from xradio.vis.read_processing_set import read_processing_set\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "intents = [\"OBSERVE_TARGET#ON_SOURCE\"]\n",
    "ps = read_processing_set(\n",
    "    ps_name=\"Antennae_North.cal.lsrk.split.vis.zarr\",\n",
    "    intents=[\"OBSERVE_TARGET#ON_SOURCE\"],\n",
    ")\n",
    "ms_xds = ps.get(1)\n",
    "\n",
    "parallel_coords = {}\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "n_chunks = 4\n",
    "parallel_coords[\"baseline_id\"] = make_parallel_coord(\n",
    "    coord=ms_xds.baseline_id, n_chunks=n_chunks\n",
    ")\n",
    "\n",
    "n_chunks = 3\n",
    "parallel_coords[\"frequency\"] = make_parallel_coord(\n",
    "    coord=ms_xds.frequency, n_chunks=n_chunks\n",
    ")\n",
    "\n",
    "display(HTML(dict_to_html(parallel_coords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00419ea6",
   "metadata": {},
   "source": [
    "### Create Node Task Data Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a04407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.coordinate_utils import (\n",
    "    interpolate_data_coords_onto_parallel_coords,\n",
    ")\n",
    "\n",
    "node_task_data_mapping = interpolate_data_coords_onto_parallel_coords(\n",
    "    parallel_coords, ps\n",
    ")\n",
    "display(HTML(dict_to_html(node_task_data_mapping)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a0e981-da9b-41f0-9b50-59d2731a57ce",
   "metadata": {},
   "source": [
    "### Map Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e3ec2-fc3b-43c2-a6d3-1d32a966a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.map import map\n",
    "import dask\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def my_func(input_parms):\n",
    "    display(HTML(dict_to_html(input_parms)))\n",
    "\n",
    "    print(\"*\" * 30)\n",
    "    return input_parms[\"test_input\"]\n",
    "\n",
    "\n",
    "# ['test_input', 'input_data_name', 'viper_local_dir', 'date_time', 'data_sel', 'chunk_coords', 'chunk_indx', 'chunk_id', 'parallel_dims']\n",
    "input_parms = {}\n",
    "input_parms[\"test_input\"] = 42\n",
    "\n",
    "graph = map(\n",
    "    input_data=ps,\n",
    "    node_task_data_mapping=node_task_data_mapping,\n",
    "    node_task=my_func,\n",
    "    input_parms=input_parms,\n",
    ")\n",
    "\n",
    "dask.visualize(graph, filename=\"map_graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbe9975-65cb-43ad-859c-72cc35ad0557",
   "metadata": {},
   "source": [
    "### Run Map Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dfee4c-4dcb-4bb9-ba12-2eca07dcea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.compute(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7f016-b05e-4773-aa2e-de8b397a0c59",
   "metadata": {},
   "source": [
    "## Time Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a8a9fe-9376-461b-b472-83107d1c1c02",
   "metadata": {},
   "source": [
    "### Create Parallel Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4acb1e-4a63-4e73-a342-30eb1013347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.coordinate_utils import make_parallel_coord\n",
    "from graphviper.utils.display import dict_to_html\n",
    "import dask\n",
    "\n",
    "dask.config.set(scheduler=\"synchronous\")\n",
    "\n",
    "from xradio.vis.read_processing_set import read_processing_set\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "intents = [\"OBSERVE_TARGET#ON_SOURCE\"]\n",
    "ps = read_processing_set(\n",
    "    ps_name=\"Antennae_North.cal.lsrk.split.vis.zarr\",\n",
    "    intents=[\"OBSERVE_TARGET#ON_SOURCE\"],\n",
    ")\n",
    "ms_xds = ps.get(1)\n",
    "\n",
    "parallel_coords = {}\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "t0, t1, t2 = (ps.get(1).time, ps.get(0).time, ps.get(2).time)\n",
    "time_coord = xr.concat([t0, t1, t2], dim=\"time\").sortby(\"time\").to_dict()\n",
    "n_chunks = 4\n",
    "parallel_coords[\"time\"] = make_parallel_coord(coord=time_coord, n_chunks=n_chunks)\n",
    "display(HTML(dict_to_html(parallel_coords[\"time\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2acace",
   "metadata": {},
   "source": [
    "### Create Node Task Data Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a71ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.coordinate_utils import (\n",
    "    interpolate_data_coords_onto_parallel_coords,\n",
    ")\n",
    "\n",
    "node_task_data_mapping = interpolate_data_coords_onto_parallel_coords(\n",
    "    parallel_coords, ps\n",
    ")\n",
    "display(HTML(dict_to_html(node_task_data_mapping)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1123fc67-58c1-4786-8546-a0fc47150dc6",
   "metadata": {},
   "source": [
    "### Map Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56f58e2-d02c-4950-9eab-9e9190660b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviper.graph_tools.map import map\n",
    "import dask\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def my_func(input_parms):\n",
    "    display(HTML(dict_to_html(input_parms)))\n",
    "\n",
    "    print(\"*\" * 30)\n",
    "    return input_parms[\"test_input\"]\n",
    "\n",
    "\n",
    "# ['test_input', 'input_data_name', 'viper_local_dir', 'date_time', 'data_sel', 'chunk_coords', 'chunk_indx', 'chunk_id', 'parallel_dims']\n",
    "input_parms = {}\n",
    "input_parms[\"test_input\"] = 42\n",
    "\n",
    "graph = map(\n",
    "    input_data=ps,\n",
    "    node_task_data_mapping=node_task_data_mapping,\n",
    "    node_task=my_func,\n",
    "    input_parms=input_parms,\n",
    ")\n",
    "\n",
    "dask.visualize(graph, filename=\"map_graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030e0b0-f289-4c16-9c74-35aab1f7b011",
   "metadata": {},
   "source": [
    "### Run Map Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e3704-6a3b-430a-a40a-457d6d751531",
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.compute(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
